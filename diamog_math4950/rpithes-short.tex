%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%                       rpithes-short.tex                         %
%         Template for a short thesis all in one file             %
%        (titlepage info below assumes masters degree}            %
%  Just run latex (or pdflatex) on this file to see how it looks  %
%      Be sure to run twice to get correct TOC and citations      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%
%  To produce the abstract title page followed by the abstract,
%  see the template file, "abstitle-mas.tex"
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{thesis}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}   % if you want to include graphics files
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\renewcommand{\algorithmicforall}{\textbf{for each}}
\let\ForEach\ForAll
% Use the first command below if you want captions over 1 line indented.
% A side effect of this is to remove the use of bold for captions. 
% To restore bold, also include the second line below.
%\usepackage[hang]{caption}     % to indent subsequent lines of captions
%\renewcommand{\captionfont}{\bfseries} % only needed with caption package;
                                        %   otherwise bold is default)
                                        
%%%%%%%%%%%%%%%%%%%%  supply titlepage info  %%%%%%%%%%%%%%%%%%%%%
\thesistitle{\bf Diffusive Load Balancing\\of Shape and Neighbor Counts}        
\author{Gerrett Diamond, Cameron Smith}        
\degree{Bachelors of Science}
\department{Mathematics} % provide your area of study here; e.g.,
%  "Mechanical Engineering", "Nuclear Engineering", "Physics", etc.
\thadviser{Mark Shephard}
%\cothadviser{First co-adviser} %if needed
%\cocothadviser{Second co-adviser} % if needed
%  For a masters project use \projadviser instead of \thadviser, 
%  and \coprojadviser and \cocoprojadviser if needed. 
\submitdate{March 2015\\(For Graduation May 2015)}        
%\copyrightyear{1685}  % if date omitted, current year is used. 
%%%%%%%%%%%%%%%%%%%%%   end titlepage info  %%%%%%%%%%%%%%%%%%%%%%
      
\begin{document} 
\titlepage             % Print titlepage   
\tableofcontents       % required 
%\listoftables          % required if there are tables
%\listoffigures         % required if there are figures

\specialhead{ABSTRACT}
Massively parallel mesh simulations require the mesh to be distributed
throughout many processes(parts) and be balanced in terms of computation and
communication. 
Many algorithms exist that target having an equal number mesh entities of a
specified dimension on each part. 
The most powerful of these, in terms of partition quality and run time are the
malt's-level (hyper)graph-based methods and the recursive geometric sectioning
methods. 
Multi-level (hyper)graph methods describe the mesh in terms of graph nodes and
(hyper)edges and then use a v-cycle of coarsening followed by un-coarsening to
divide the graph into subgraphs while recursive sectioning geometric methods use
a coordinate system such as the Cartesian location or centroids to recursively
section the mesh along coordinate or inertial axis. 
The faster geometric methods tend to create parts that have large inter-part
surface area, and many neighbors relative to the (hyper)graph based methods
which causes an increase in communication.
(Hyper)Graph-based methods can also suffer from similar issues as the number of
parts gets very large and the number of elements per part drops to several
hundreds. 
An alternative method that uses mesh data directly, ParMA, performs load 
balancing without the need to construct a graph. 
With access to all the mesh, partition, and model data, including topological 
and geometric coordinates, partitioning methods analogous to those used by 
(hyper)graph and geometric based procedures can be defined.
Towards this, ParMA partitioning methods will be extended to improve the 
overall shape of a part in order to reduce the number of neighbors each part 
has and thus reduce application communication times.

\chapter{INTRODUCTION}
The text of the first chapter goes here. 


\section{Motivation}
In various applications it is important to reduce the average number of 
neighbors a part has. If parts share boundaries with many neighbors there will 
be lots of time spent sending and receiving information from each part's 
neighbors.

%describe terminology (heavy vs light parts)
\section{Definition of mesh and graph terminology} 


\chapter{Related Works}
Many different distributed methods to balance unstructured meshes have been 
explored in the past \cite{multidiffuse,surveygraph}. Here we discuss the 
three most commonly used methods: graph/hypergraph, diffusive, and multilevel.

\section{(Hyper)graph methods}
Graph and Hypergraph load balancing methods use an abstraction of the mesh in 
order to balance the work load between processes. The first step to using 
hypergraph/graph methods is creating this abstraction. Zhou et al. define that 
the graph nodes are built off of a specific mesh entity typically either faces 
for 2D or regions for 3D \cite{zhougraph}. The edges are then built based on the
dependencies of the nodes. In their work they found that using only a subset of 
these edges is sufficient for the same quality of partition. For their work with
regions as nodes they found using the face adjancencies gave just as good a 
partition in much less time. The authors also define two different types of 
edges: Interedges that connect graph nodes on different processors and 
intraedges that connect graph nodes on the same processor. Zhou describes the 
hypergraph as an extension of the graph where hypergraph nodes are the same as 
graph nodes, but hypergraph edges or hyperedges represent dependencies between 
more than one mesh entity. Thus hyperedges can correlate each entity with all 
of its face adjancencies. The overall goal of hypergraphs and hyperedges is to 
partition the graph while minimizing the number of parts the hyperedges extend 
over.

Buluc et al. \cite{surveygraph} give an overview of graph methods in the field 
for both graphs and hypergraphs. They also discuss the challenges and 
NP-hardness of many of the algorithms for graph balancing. Two metrics that 
are used to model the overall shape for graph methods are the edge cut and 
communication volume. The authors show that communication volume is a better 
measurement which leads to hypergraph methods which better target the 
communication volume because hyperedges represent the number of different 
neighboring parts to each node in the graph. Devine et al. discuss methods 
to use hypergraphs for parallel scientific computing \cite{hypergraph}. They
use hypergraphs to accurately represent communication volume and as a result
part neighbors. The hypergraph method uses hyperedges or nets which connects 
several nodes in the graph that may be on different parts. Therefore 
balancing a hypergraph naturally puts an effort towards balancing the overall
shape and neighbors of parts. 

Graph and Hypergraph methods for load balancing are said to be the most 
effective \cite{zhougraph,surveygraph}. Still there are some draw backs 
presented by Zhou et al. \cite{zhougraph}. First off since the graph targets 
a specific dimension, the other dimensions can become unbalanced. Also 
graph/hypergraph methods do not scale well when working with more than 
100,000 processors. The authors explain that using both local partitioning 
and global partitioning can result in good partitions that can scale out to
large part counts. Also with large part counts some parts become much 
heavier than others which limits the scalability of these methods.

\section{Diffusive load balancing}
Willebeek-LeMair and Reeves describe diffusive load balancing techniques with 
four steps \cite{loadbalance}. The first is evaluating the processor load, then 
determining the profitability of the load balancing, followed by a task 
migration strategy, and finally a task selection strategy. They review over 
five different strategies and how they perform on the second and third task. 
The first method reviewed was the Sender Initiated Diffusion method (SID). 
This method restricts parts to only communicate with their neighbors and the 
heavy parts or senders are the migration selectors. The second technique is 
similar to the first and called Receiver Initiated Diffusion (RID). Once again 
parts can only communicate with their neighbors, but instead of the heavy parts
selecting migration targets, the light parts select heavier neighbors to receive
load from. Our method for shape optimization is similar to the idea of a RID 
method. In the Gradient Method (GM), light parts inform nearby parts in search 
of a heavy part which causes heavy parts to send load towards the closest light 
part. The Hierarchical Balancing Method (HBM) breaks up load balancing into a 
hierarchy of parts and performs load balancing at a low level and then continues
to balance while moving up a hierarchy. The final method is the Dimension 
Exchange Method (DEM). Similar to the HBM, the DEM approach balances at a low 
level and works up, but the DEM balances synchronously in all dimensions one at 
a time.

Zhou et al. developed a diffusive algorithm to balance the heavy parts produced 
by graph/hypergraph methods \cite{zhougraph}. They target balancing the mesh vertices for each
part of the partition by offloading certain entities from heavy parts to 
lighter parts. Their method, the local iterative interpart boundary 
modification algorithm (LIIPBMod), identifies mesh vertices on the heavy parts
that are bounded by a small number of elements. By doing this, LIIPBMod 
balances the vertex partitioning while still maintaining the element balance
produced from the graph/hypergraph partition. This process when repeated 
results in a partition that has vertex balance with a minor decrease in the 
good element balance. The results of their method shows a dramatic improvement
of vertex imbalance sometimes reducing from over 20\% to around 5\%. They 
discuss that the scaling is not so significant because much more time is spent 
on the graph/hypergraph partitioning than their method.


\section{Multilevel methods}
Buluc et al. describe the multilevel methods as the most successful approach to 
graph partitioning \cite{surveygraph}. They describe multilevel methods 
generally as a three step process. The first step is to coarsen the mesh 
until some threshold in order to reduce complexity. The second is to create 
an initial partition of this fully coarsened mesh that can be done much 
faster than the entire mesh. Next the mesh is refined in the opposite direction
of the coarsening. At each step the mesh is progressively refined in order to
keep the balance across the parts. This design is called a v-cycle. The 
generality of the design allows most algorithms to be altered to work in a 
multilevel form. 

Meyerhenke et al. port a diffusive method previously used for 
shape optimization into a multilevel algorithm \cite{multidiffuse}. They use a 
previously used distributed load balancing algorithm, Bubble-FOS/C (First order
diffusion scheme with constant drain) for load balancing in their multilevel
method. This Bubble method is an iterative scheme based on Lloyd's k-means 
algorithm. This method involves solving linear systems repeatedly which causes 
a high run time. Thus the authors introduce a second balancing algorithm, 
TruncCons (truncated diffusion consolidations), into the v-cycle. This 
algorithm is faster than Bubble for large mesh sizes and is used for small
diffusive improvements. They use the multilevel structure in order to use 
the expensive but more effective Bubble-FOS/C when at the small levels of the 
v-cycle and then use TruncCons to balance the larger parts of the v-cycle. 
This method was shown to be much faster than the original method 
of just the Bubble-FOS/C and also produces a better quality of load balancing. 
They compared this new method to the popular methods KMetis and JOSTLE and 
found their method to produce higher quality partitions but still having a
much higher run time. They expect reasonable scaling for the algorithm but 
results show the algorithm taking minutes rather than seconds like other 
methods.

\chapter{Method}

The approach we take to fixing small sides builds off a parallel 
dynamic partitioning framework called ParMA \cite{parma}. Thus our algorithm, Gap,
 defines a series of steps defined in the ParMA load balancing method to target
 small sides and migrate elements to increase the size of these boundaries. Here 
we describe the base framework of ParMA and how it is extended to create Gap.

\section{ParMA}

ParMA load balancing methods follow a five step plan. These five steps 
are the sides determination, weight assignment, target phase, selection
phase, and the stepper phase. The sides determination is when each part 
determines which parts are its neighbors. These sides are defined for some
 dimension $d$ as a part that shares a $M^d$ entity. After sides are 
determined, the weight assignment phase collects the weight (for a certain 
mesh entity order (vertex, edge, face, or region)) of the neighbor parts 
defined by the sides. The 
target phase defines which parts will be sending and the parts each one 
will be sending to. The target phase also defines an amount of weight to 
be transferred from each sending part to each of its targets. The selection 
phase determines which elements of the mesh will be sent to the targets 
until the given amount of weight is satisfied. The final stepper phase is 
to migrate the elements between each part and complete the load balancing 
step. These steps are repeated until a stopping criteria is satisfied 
during the stepper phase. 

Each diffusive load balancing algorithm derived from ParMA implements these 
steps to target the criteria of the algorithm \cite{parma}. The most important 
steps of the ParMA framework is the target phase and selection phase which 
defines the problem specific actions that will be taken to balance the parts. 
The stopping criteria is typically to go below some balancing threshold of 
a given mesh entity order(s). We define the balancing threshold to be a 
percent imbalance of the given mesh entity order among all of the parts. 
The percent is typically between 1\% and 10\%. The stopping criteria can also 
be appended to include problem specific endpoints.
 
  
\section{Gap}

Gap derives from ParMA and thus must define the phases in order to target 
small boundaries and select elements around the small boundaries in order 
to increase the length of these small sides. 

\subsection{Vertex Sides}

For sides, we decide to use vertex sides ($d$=0) in order to represent the 
boundaries between two parts. We choose this in order to locate single vertex 
boundaries between parts. Fixing these single vertex junctions allows gap to 
decrease the number of neighbors by turning the single vertex junction into 
an edge. The sides are also used to count how many vertices a given boundary 
has. This quantifies the length of the boundaries for the later phases of the 
algorithm.

\subsection{Receiver based targeting}

%General Discussion
Gap uses a reverse method of deciding targets. The targets of Gap are the 
parts that share a small boundary. To detect these small boundaries the 
targets must detect them rather than the senders. Therefore, Gap implements 
a receiver based targeting where parts detect that they are receivers and 
inform the sending parts to send elements to the receivers. 

%Description of Algorithm
Algorithm \ref{alg:targets} outlines the method for finding small sides 
and determining the sending parts. First each part finds the smallest 
boundary it has and checks if the length of this boundary is less than 
some percentage of the average length of all boundaries. Each iteration 
the percentage that is multiplied by the average side length increases 
towards 100\%. Once the small sides are found, pairs of parts that share 
these small boundaries attempt to confirm each other. All of the matches 
that are found become the receivers of this step. The receivers then 
traverse along the small boundary to find the parts that share a vertex 
with the two receiving parts. Figure \ref{fig:boundary} shows an example 
of this. Parts \# and \# detect the small boundary which then determine 
parts \# and \# as the senders. The receivers then send messages to the 
senders to inform them. At that point the senders set each receiver as a 
target and calculates the weight to send to the targets.

\begin{algorithm}
\caption{Gap Target phase}
\label{alg:targets}
\begin{algorithmic}[1]
\Require {mesh $M$ of dimension $d$, sides $s$, weights $w$}
\Procedure{targets}{$M$, $s$, $w$}
  \State $targets \leftarrow \emptyset$
  \If {part is in MIS subset AND smallest\_side$<$tolerance}
    \State $other = $ part opposite small side
    \State send message to $other$
  \EndIf
  \If {receives message}
    \State $other = $ message sender
    \State $senders \leftarrow findNeighbors() - self - other$
  \EndIf
  \ForEach {$send \in senders$}
    \State send self and other in message to send
  \EndFor
  \If {receives message}
    \State $targets \leftarrow [firstpart,calcWeight(first)]$
    \State $targets \leftarrow [secondpart,calcWeight(second)]$
  \EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

% Maximal Independent Set
One problem that can occur during the target phase is if a part is 
designated as a receiver and a sender. This causes elements to be sent 
to the part and from the part in the same migration which will cause 
disconnected components throughout the boundary between the parts. Figure 
\ref{fig:recvsend} depicts this error and shows the direction of the element 
sending. [Describe more about the figure]. Our solution to this problem is 
to not allow neighboring parts to send to each other by using a  maximal 
independent sets (MIS) on non-neighboring parts. We used Luby's randomized 
parallel MIS algorithm \cite{luby} to separate which parts find the small 
boundaries. This separates parts into subsets such that none of the parts 
within a subset are neighbors to each other. Thus each step of the load 
balancing algorithm uses a different subset from the maximal independent sets. 
So the first part of the target phase is each part in the MIS subset 
finds its smallest side. If this side is less than the percent of the average 
side length then it sends a message to the part on the other side of the 
boundary. This other part then determines the senders and the rest of the 
algorithm follows. These changes to the target phase are included in Algorithm 
\ref{alg:targets}. The MIS subsets guarantee that two adjacent parts cannot 
find small sides that would cause the sender and receiver conflict. 

\subsection{Selection by Centroid}
After targets have been found each sender must choose which elements close 
to the small side will be migrated to the neighboring parts and which part 
each element will migrate to. To do this Gap's selection phase uses geometric 
centroids to determine which elements to send first and which part will 
receive them. The process begins with the sender part determining a seed 
element that is vertex adjacent to the small side. As there is likely 
multiple elements adjacent to the small side boundary we use the element 
that is furthest from the centroid of the part. This is found by the euclidean 
distance from the element's centroid to the part's centroid. Once the seed 
element is selected additional elements are chosen that 
are adjacent by one mesh entity order less than the dimension of the mesh 
(edge in two dimensions and face in three dimensions). Each additional edge 
is added to a priority queue that is sorted by the distance of the element 
to the part centroid. This queue is traversed continuously adding more 
elements until the sum of the elements weight sent is greater than the total 
weight calculated in the targets phase. This selection causes the sender 
parts to become rounder as the furthest away elements are sent first.

Since each sender has two target parts, one on each side of the small 
boundary, each element to be migrated must choose one of the target parts to 
migrate to. We choose to send each element to the closest part geometrically. 
The closeness of an element to a part is defined as the euclidean distance 
from the elements centroid to the target part's centroid. Thus the element 
is migrated to the receiving part that has the lower of these distances. 
These migration choices lead to the small side being extended towards the 
sender parts. A simple example is shown in Figure \ref{fig:selection}. Here 
the small side is between parts \# and \#. The black represents the initial 
boundary lines and the red is the boundaries after a step of the shape 
balancing.

\subsection{Stopping Criteria}
Gap does not directly attempt to decrease the imbalance of entities within 
the mesh. In fact, Gap will sacrifice imbalance in order to achieve an improved 
shape quality. Therefore the stopping criteria for Gap is when it goes above a 
given level of imbalance. In addition to the imbalance criteria Gap also 
finishes once the minimum boundary length is greater than a percentage of the 
original average boundary length. With both of these conditions Gap will 
complete if the mesh becomes too imbalanced or the smallest sides have been 
widened towards the average. For our tests we used 20\% imbalance and 70\% 
of the initial average side length. We choose 20\% imbalance because this 
imbalance is still easily fixed by ParMA entity imbalance improvement 
[CITE ParMA paper?].

\chapter{Results}

\section{Metrics of shape}


\section{Plate testing}

Our initial testing of Gap has been done on a two dimensional flat plate mesh. A 16 part version of the plate mesh partitioned by  the Recursive Inertial Bisection (RIB) method [Reference? idk] is included in Figure \ref{fig:plate}. 

\chapter{Limitations and Future Work} 

%Geometric centroids to topological centroids
Gap is a work in progress and as such has several extensions required to make 
it a more general algorithm. First of all as seen in the images after being 
balanced by gap \ref{fig:gap1...n},  the boundaries are jagged which allows a 
longer boundary length but a smoother boundary would be ideal. These jagged 
boundaries are a result of using geometric centroids to compute distances for 
migration selection. The geometric centroid takes no topological information 
into account which causes the topology to be sacrificed in order to achieve the 
goal. In future testing we would like to try using topological centroids 
instead of geometric centroids. (describe what topological centroids are)

%Small Isolated Components and non fixable regions
Due to the nature of Gap's targeting, there are some regions that cannot be 
fixed by Gap. Namely these are areas where there are no sender parts around 
the boundary between two parts which can be see in Figure \ref{fig:ocean}. 
Currently if one of these regions is the smallest side between the two parts, 
the parts will continuously try to fix those small sides rather than target 
ones that have sender parts incident on the small side. We would like to have 
Gap ignore these unfixable boundaries in order to target small sides that can 
be fixed by the algorithm.

%Multiple boundaries 


%Exchanging elements that revert a previous change

\chapter{Closing Remark}

We presented a method to improve the shape of a mesh in order to reduce costs of communication across different processes.
% The following produces a numbered bibliography where the numbers
% correspond to the \cite commands in the text.
\specialhead{LITERATURE CITED}
\begin{singlespace}
\begin{thebibliography}{99}
\bibitem{multidiffuse} Meyerhenke, H.; Monien, B.; Sauerwald, T., "A new 
diffusion-based multilevel algorithm for computing graph partitions of very 
high quality," Parallel and Distributed Processing, 2008. IPDPS 2008. IEEE 
International Symposium on , vol., no., pp.1,13, 14-18 April 2008
\bibitem{diffuseshape} Ralf Diekmann, Robert Preis, Frank Schlimbach, Chris 
Walshaw, Shape-optimized mesh partitioning and load balancing for parallel 
adaptive FEM, Parallel Computing, Volume 26, Issue 12, November 2000, Pages 
1555-1581, ISSN 0167-8191, http://dx.doi.org/10.1016/S0167-8191(00)00043-0.
\bibitem{loadbalance} Willebeek-LeMair, M.H.; Reeves, AP., "Strategies for 
dynamic load balancing on highly parallel computers," Parallel and Distributed 
Systems, IEEE Transactions on , vol.4, no.9, pp.979,993, Sep 1993
\bibitem{zhougraph} Zhou M, Sahni O, Devine KD, Shephard MS, Jansen KE (2010) 
Controlling unstructured mesh partitions for massively parallel simulations. 
SIAM J Sci Comput 32:3201â€“3227
\bibitem{surveygraph} A. Buluc, H. Meyerhenke, I. Safro, P. Sanders, and C. 
Schulz, Recent advances in graph partitioning , (2013), p. arXiv:1311.3144.
\bibitem{hypergraph}  Karen D. Devine , Erik G. Boman , Robert T. Heaphy , 
Rob H. Bisseling , Umit V. Catalyurek, Parallel hypergraph partitioning for 
scientific computing, Proceedings of the 20th international conference on 
Parallel and distributed processing, p.124-124, April 25-29, 2006, Rhodes 
Island, Greece 
\bibitem{parma} Smith, C.W., Rasquin, M., Ibanez, D., Jansen, K.E., Shephard,
M.S., "Application Specific Mesh Partition Improvement", Submitted to SIAM Journal on Scientific Computing, 2015.
\bibitem{luby} M Luby. 1985. A simple parallel algorithm for the maximal independent set problem. In Proceedings of the seventeenth annual ACM symposium on Theory of computing (STOC '85). ACM, New York, NY, USA, 1-10. DOI=10.1145/22145.22146 
\end{thebibliography}
\end{singlespace}

\end{document}
